---
---

@string{aps = {American Physical Society,}}

@InProceedings{DSP,
    abbr={COCONET},
    bibtex_show={true},
    author={Gunisetty, Srivatsav and Bommerla, Vamshi Krishna and Dasari, Mokshanvitha and Chava, Vennela and Gopakumar, G.},
    editor={Thampi, Sabu M. and Gelenbe, Erol and Atiquzzaman, Mohammed and Chaudhary, Vipin and Li, Kuan-Ching},
    title={Dynamic Search Paths for Visual Object Tracking},
    booktitle={Advances in Computing and Network Communications},
    year={2021},
    publisher={Springer Singapore},
    address={Singapore},
    pages={379--388},
    abstract={The long-term sub-track of visual object tracking challenge comprises of some of the most challenging scenarios like occlusion and target disappearance and reappearance. To this end, many deep learning solutions with multiple levels of detection have been proposed. Most of these solutions tend to re-identify a wrong target during the occlusion or disappearance as they start looking for the target in the entire frame. Instead, through this work, we intend to prove that predicting a probable search region for the target by understanding its trajectory and searching for a target in it will help in reducing the misidentifications and also aid in the increase of IoU. For this, we have utilized the trajectory modeling capabilities of the Kalman filter. With this proof of concept work, we achieved an average improvement of 37.37{\%} in IoU in the sequences where we overperformed MBMD.},
    isbn={978-981-33-6987-0},
    html={https://link.springer.com/chapter/10.1007/978-981-33-6987-0_31}
}

@INPROCEEDINGS{CoIn,
    abbr={ICACCS},
    bibtex_show={true},
    author={Vanishree, K. and George, Anu and Gunisetty, Srivatsav and Subramanian, Srinivasan and Kashyap R., Shravan and Purnaprajna, Madhura},
    abstract={In Convolutional Neural Networks (CNN), the need for low inference time per batch is crucial for real-time applications. To improve the inference time, we present a method (CoIn) that benefits from the use of multiple devices that execute simultaneously. Our method achieves the goal of low inference time by partitioning images of a batch on diverse micro-architectures. The strategy for partitioning is based on offline profiling on the target devices. We have validated our partitioning technique on CPUs, GPUs and FPGAs that include memory-constrained devices in which case, a re-partitioning technique is applied. An average speedup of 1.39x and 1.5x is seen with CPU-GPU and CPU-GPU-FPGA co-execution respectively. In comparison with the approach of the state-of-the-art, CoIn has an average speedup of 1.62x across all networks.},
    booktitle={2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)},   
    title={CoIn: Accelerated CNN Co-Inference through data partitioning on heterogeneous devices},   
    year={2020},  
    pages={90-95},  
    doi={10.1109/ICACCS48705.2020.9074444},
    html={https://ieeexplore.ieee.org/abstract/document/9074444}
}